name: Scrape & Load Events

on:
  schedule:
    - cron: '0 0 * * *' # daily at 12:00 AM UTC
  workflow_dispatch:
    inputs:
      skip_geocoding:
        description: 'Skip geocoding step (saves API quota)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

jobs:
  scrape:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: data_extraction/event_scraper

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: data_extraction/requirements.txt

      - name: Install dependencies
        run: pip install -r ../requirements.txt

      - name: Install Playwright browsers
        run: playwright install --with-deps chromium

      - name: Run pipeline
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          base_geo: ${{ secrets.BASE_GEO }}
        run: |
          if [ "${{ github.event.inputs.skip_geocoding }}" = "true" ]; then
            python run_pipeline.py --skip-geocoding
          else
            python run_pipeline.py
          fi

      - name: Upload scraped data as artifact (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraped-data-${{ github.run_id }}
          path: |
            data_extraction/event_scraper/data/
            data_extraction/event_scraper/cleaned_data/
            data_extraction/event_scraper/logs/
          retention-days: 3
